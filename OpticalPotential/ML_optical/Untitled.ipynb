{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b5b47f-cfc1-4959-b37d-a93ed1b28834",
   "metadata": {},
   "source": [
    "# OMP Machine Learning project\n",
    "\n",
    "* The project aims to construct a neural network which generate optical model potential parameters.\n",
    "* As a first step, let us only consider spin-zero particles and optical potential of Woods-Saxon form. \n",
    "* The main idea is to construct two neural networks and train them separately. Because optical potential parameters are not physical observavbles, one cannot directly train the NN to generate optical potential parameters. \n",
    "* One neural network(NN-A) takes inputs such as (projectile mass and charge),(target mass and charge),(projectile energy),(Optical potential parameters), (angle). And output of NN is (differential cross section)\n",
    "* The other neural network (NN-B) takes inputs (projectile mass and charge),(target mass and charge),(projectile energy),(angle). And the output of NN are (Optical potential parameters). \n",
    "* The first NN-A will be trained with pseudo-data generated by usual reaction codes. Thus, NN-A would acts as a pseudo-Shrodinger equation solver. Once the trainning is done, we will fix the NN's parameters.\n",
    "* The NN-B will be connected in front of NN-A. So that combined NN has ooutput of (differential cross section). \n",
    "  The combined neural network will be trained with experimental data. Because NN-A is fixed, the training will determine the parameters of NN-B only. \n",
    "* Once the training of combined NN is done, we detach the NN-A and NN-B. Then, NN-B will act like a optical potential generator.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ca60c-a3f1-4de6-b50f-7fd4836dad40",
   "metadata": {},
   "source": [
    "## simple NN-A\n",
    "\n",
    "* Let us start from the construction of NN-A. At the moment, let us not consider details of the actual input and output but focus on making a skeleton of the code.\n",
    "* In actual work, we have to decide how the input and output are prepared(normalization, file structure and so on.). Also, the structure of neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fd59d-2ae6-453a-9965-43bd226b0dd5",
   "metadata": {},
   "source": [
    "### import required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b647f3-20fd-4775-be3a-e1a3730cdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# convert integer to array \n",
    "def integer_to_bin_array(N,dim_b=8):\n",
    "    \"\"\" Convert integers into dim_b bits  binary\n",
    "    \"\"\"\n",
    "    bin_str = bin(N)[2:] # to binary string \n",
    "    if len(bin_str) > dim_b :\n",
    "        raise ValueError('{} is too large to be {} bits'.format(N,dim_b))\n",
    "    bin_str=bin_str.zfill(dim_b) #padding zero \n",
    "    bin_array=[float(j) for j in bin_str] \n",
    "    return bin_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bbd90-81c2-4906-95c2-ba7a7a65514b",
   "metadata": {},
   "source": [
    "### global options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59b21c7-66e4-476a-922e-79a317bca5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---model related\n",
    "opt_model_load = False   # whether to read model parameters from file\n",
    "opt_model_save = False   # whether to save the model parameters to file\n",
    "opt_model_train = True   # whether to train/update the model parameters \n",
    "model_filename = 'my_model.h5' # filename to save models\n",
    "#---training data related (Because preprocessing can be different.) \n",
    "opt_data_load = True     # whether to load pre-prepared data sets\n",
    "opt_data_save = False    # whether to save pre-prepared data sets\n",
    "dataset_filenames = ['train_dataset','test_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69426bca-09c3-41e9-be98-a478ddb38a87",
   "metadata": {},
   "source": [
    "### data preparation\n",
    "\n",
    "We may prepare data as a dictionary with keys.\n",
    "Keys can be 'AP','ZP','AT','ZT','Elab','angle'. 'dsigma'\n",
    "In other words, \n",
    "\n",
    "data={'AP': [arrays],'ZP':[arrays] ...} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32c75b-614e-4a74-ad12-4373f8e47cf3",
   "metadata": {},
   "source": [
    "### Simple Model construction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a55f53-e5f4-44b7-931b-4ff0dd874742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2010533 , 0.00313118, 0.17291343, 0.00689775, 0.61600435]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.predict([ [1,2,3]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
