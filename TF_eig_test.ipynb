{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0fa54b9-5238-4d9b-a544-dff9e099c6a2",
   "metadata": {},
   "source": [
    "# Tensorflow for eigenvalue problem\n",
    "\n",
    "Testing audograd for eigenvalue problem. Or PMM(Parametric Matrix Model) \n",
    "\n",
    "Suppose True problem have eigenvalues $e_t(c)$.\n",
    "Prepare random matrix\n",
    "$M(c) = M_0 + c M_1$, and solve eigenvalue problem $M(c) v = e v$. \n",
    "\n",
    "The goal is to reduce the difference $|e(c)-e_t(c)|^2$\n",
    "by updating matrix $M_0$ and $M_1$. In other words, obtaining \n",
    "$M(c)$ which simulate the original problem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d60d07e-48ae-4cde-b9e2-51f4f23b88ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\young\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#========== import packages=============== \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.get_logger().setLevel('ERROR')\n",
    "#tf.autograph.set_verbosity(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62139237-d1d3-4e83-93e2-e2f5048ada66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm_t :[[ 0.5+0.j  1. +0.j]\n",
      " [ 1. +0.j -0.5+0.j]] \n",
      "e_t :[ 1.11803399+0.j -1.11803399+0.j] \n",
      "mm(0) :[[ 1.1+0.j   0.5-0.1j]\n",
      " [ 0.5+0.1j -0.9+0.j ]] \n",
      "e(0) :[-1.02249722+6.30407896e-18j  1.22249722-6.30407896e-18j] \n"
     ]
    }
   ],
   "source": [
    "#============set up matrix====================\n",
    "# target true matrix\n",
    "c= tf.constant(0.5,dtype=tf.complex128)\n",
    "s0 = tf.constant( [ [1.0,0.0],[0.0,1.0]],dtype=tf.complex128)\n",
    "sx = tf.constant( [ [0.0,1.0],[1.0,0.0]],dtype=tf.complex128)\n",
    "sy = tf.constant( [ [0.0+0j,-1j],[1j,0.0+0j]],dtype=tf.complex128)\n",
    "sz = tf.constant( [ [1.0,0.0],[0.0,-1.0]],dtype=tf.complex128)\n",
    "\n",
    "def mm_t(c):\n",
    "    return sx+ sz*c \n",
    "\n",
    "e_t,v_t = tf.linalg.eig(mm_t(0.5))\n",
    "\n",
    "#------initial matrix\n",
    "learning_rate=tf.constant(0.01,dtype=tf.complex128)\n",
    "var = tf.Variable([0.1,0.5,0.1,1.0],dtype=tf.complex128) # true is (0,1,0,0.5)\n",
    "\n",
    "def mm_var(var):\n",
    "    return s0*var[0]+sx*var[1]+sy*var[2]+sz*var[3]\n",
    "\n",
    "e,v = tf.linalg.eig(mm_var(var))\n",
    "\n",
    "print('mm_t :{} '.format(mm_t(0.5)))\n",
    "print('e_t :{} '.format(e_t))\n",
    "print('mm(0) :{} '.format(mm_var(var)))\n",
    "print('e(0) :{} '.format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba21079d-bf63-41d1-8bde-bcaf827cfc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#----compute loss and record tape \n",
    "def one_step(var):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #print('mat:\\n {}'.format(mm.numpy()))     \n",
    "        e,v = tf.linalg.eig(mm_var(var))\n",
    "        #print('e(0) :{} '.format(e))\n",
    "        loss = tf.math.reduce_sum(tf.math.abs(e-e_t)**2)\n",
    "        print('loss: {}'.format(loss.numpy()))     \n",
    "        #---update\n",
    "    dvar = tape.gradient(loss,var)\n",
    "    var = tf.Variable(var - dvar*learning_rate,dtype=tf.complex128)\n",
    "    return var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5857098c-1bd8-46b1-80da-1d4e622e7fad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10.059960159204447\n",
      "loss: 9.27125928272282\n",
      "loss: 8.544392554957348\n",
      "loss: 7.874512178648692\n",
      "loss: 7.257150423842635\n",
      "loss: 6.688189830613372\n",
      "loss: 6.163835747893286\n",
      "loss: 5.680591025258451\n",
      "loss: 5.235232688878189\n",
      "loss: 4.824790446070139\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    var = one_step(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b63b101-cc3a-442f-b0f4-6e34aabcb1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(4,) dtype=complex128, numpy=\n",
      "array([0.06648326-8.98145931e-19j, 0.16549898-1.66533454e-18j,\n",
      "       0.0330998 +8.88178420e-18j, 0.33099795+1.32230012e-18j])>\n",
      "tf.Tensor([-0.30506101+5.00740002e-18j  0.43802754+2.35564807e-18j], shape=(2,), dtype=complex128)\n",
      "tf.Tensor([ 1.11803399+0.j -1.11803399+0.j], shape=(2,), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "e,v = tf.linalg.eig(mm_var(var))\n",
    "print(var)\n",
    "print(e)\n",
    "print(e_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96148f54-cfe5-4ef0-ad13-5d26ea30f34a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### It is not clear how to use Adam optimizer in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714131c7-2804-4359-97ac-4dff44ffa095",
   "metadata": {},
   "source": [
    "# PyTorch test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef426f-6cbd-4f1a-baa0-edbc829301e1",
   "metadata": {},
   "source": [
    "## test with simple gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b6d35c-0a5e-4069-aa93-607602a6c75a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<SumBackward0>)\n",
      "tensor(0.2990, grad_fn=<SumBackward0>)\n",
      "tensor([ 1.5305+0.j, -0.8674+0.j], grad_fn=<LinalgEigBackward0>) tensor([ 1., -1.])\n"
     ]
    }
   ],
   "source": [
    "#-----testing pytorch\n",
    "import torch\n",
    "from torch import FloatTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "w = Variable(FloatTensor([[4,2],[2,1]]),requires_grad=True)\n",
    "ee,vv = torch.linalg.eig(w)\n",
    "e_t = torch.Tensor([ 1.0,-1.0]) # target eigenvalues\n",
    "\n",
    "def get_loss(ee,e_t):\n",
    "    return (torch.abs(ee-e_t)**2).sum()\n",
    "loss = get_loss(ee,e_t)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "dw = w.grad\n",
    "\n",
    "for i in range(100):\n",
    "    w =  Variable(w-dw*0.01,requires_grad=True) \n",
    "    ee,vv = torch.linalg.eig(w)\n",
    "    loss = get_loss(ee,e_t)\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    dw = w.grad\n",
    "print(loss) \n",
    "print(ee,e_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d867a-3c91-4587-9f17-b589e02420f0",
   "metadata": {},
   "source": [
    "## test with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a70445-5b60-4451-8f39-d35f6123f3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = Variable(FloatTensor([[4,2],[2,1]]),requires_grad=True) # prepare variable\n",
    "optim = torch.optim.Adam([w],lr=0.01)\n",
    "#optim = torch.optim.SGD([w],lr=0.01)\n",
    "ee,vv = torch.linalg.eig(w)\n",
    "loss = get_loss(ee,e_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9c4c00-bb6b-4200-9c8f-3589c8b1ffc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<SumBackward0>)\n",
      "tensor(15.6997, grad_fn=<SumBackward0>)\n",
      "tensor([ 4.8388+0.j, -0.0186+0.j], grad_fn=<LinalgEigBackward0>) tensor([ 1., -1.])\n"
     ]
    }
   ],
   "source": [
    "#--test model construction in Pytorch\n",
    "print(loss)\n",
    "for i in range(10):\n",
    "    ee,vv = torch.linalg.eig(w)\n",
    "    loss = get_loss(ee,e_t)\n",
    "    #print(loss)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "print(loss)    \n",
    "print(ee,e_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cf801-cf17-45a5-9481-d63627fd409b",
   "metadata": {},
   "source": [
    "## test with the same problem as tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f807896a-a5d5-42f2-8a9b-1517e2798731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c= 0.5\n",
    "s0 = torch.tensor( [ [1.0,0.0],[0.0,1.0]])\n",
    "sx = torch.tensor( [ [0.0,1.0],[1.0,0.0]])\n",
    "sy = torch.tensor( [ [0.0+0j,-1j],[1j,0.0+0j]],dtype=torch.complex64)\n",
    "sz = torch.tensor( [ [1.0,0.0],[0.0,-1.0]])\n",
    "\n",
    "def mm_t(c):\n",
    "    return sx+ sz*c \n",
    "\n",
    "e_t,v_t = torch.linalg.eig(mm_t(0.5))\n",
    "\n",
    "#------initial matrix\n",
    "learning_rate=torch.tensor(0.01)\n",
    "var = Variable(torch.tensor([0.1,0.5,0.1,1.0]),requires_grad=True) # true is (0,1,0,0.5)\n",
    "optim = torch.optim.Adam([var])\n",
    "\n",
    "def mm_var(var):\n",
    "    return s0*var[0]+sx*var[1]+sy*var[2]+sz*var[3]\n",
    "\n",
    "def get_loss(ee,e_t):\n",
    "    return (torch.abs(ee-e_t)**2).sum()\n",
    "\n",
    "ee,vv = torch.linalg.eig(mm_var(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e79395-6a49-442f-950a-4e0420b039ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_loss(ee,e_t))  \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      3\u001b[0m     ee,vv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meig(mm_var(var))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_loss' is not defined"
     ]
    }
   ],
   "source": [
    "print(get_loss(ee,e_t))  \n",
    "for i in range(100):\n",
    "    ee,vv = torch.linalg.eig(mm_var(var))\n",
    "    loss = get_loss(ee,e_t)\n",
    "    #print(loss)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "print(loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9c930-d381-49ea-b95e-c44b68cf8d8a",
   "metadata": {},
   "source": [
    "Note that two matrices , mm_t and mm_var is not necessarily be the same matrices.\n",
    "They only share the eigenvalues and could be related with unitary transformation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511c6546-fc24-45f5-a31e-cf26c219e1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meig(mm_var(var)))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meig(mm_t(\u001b[38;5;241m0.5\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.eig(mm_var(var)))\n",
    "print(torch.linalg.eig(mm_t(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8158a-561f-474c-9c2e-d7bca704c02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
